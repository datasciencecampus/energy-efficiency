{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Driven Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EPC data contains several categorical variables with a lot of values. In order to find suitable features which will retain the most information, three feature sets are explored;\n",
    "* data driven\n",
    "* domain driven\n",
    "* exhaustive\n",
    "The first approach, termed data driven, uses statistical methods to reduce the number of variables. As the variables containing textual descriptions of the property have been created free-hand, many contain a large number of unique values. In some cases, only recorded for one property. The data driven approach uses a single level Chi-square Automatic Interaction Detector (CHAID) to group the levels within each categorical variable into a smaller number of groups. CHAID groups values with a similar response rate or in this context Energy Efficiency Rating (EER).\n",
    "\n",
    "This script applies the groupings from the CHAID and bins the numerical fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables from config file\n",
    "config_path = os.path.abspath('..')[:-7]\n",
    "\n",
    "with open(config_path + '/config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "processing_path = config['DEFAULT']['processing_path']\n",
    "epc_train_clean_fname = config['DEFAULT']['epc_train_clean_fname']\n",
    "epc_test_clean_fname = config['DEFAULT']['epc_test_clean_fname']\n",
    "epc_train_data_fname = config['DEFAULT']['epc_train_dd_fname']\n",
    "epc_test_data_fname = config['DEFAULT']['epc_test_dd_fname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {'INSPECTION_DATE':'str'}\n",
    "\n",
    "epc_train = pd.read_csv(os.path.join(processing_path,epc_train_clean_fname),header = 0,delimiter = ',',dtype = dtype_dict,\n",
    "                        parse_dates = ['INSPECTION_DATE'])\n",
    "epc_test = pd.read_csv(os.path.join(processing_path,epc_test_clean_fname),header = 0,delimiter = ',',dtype = dtype_dict,\n",
    "                        parse_dates = ['INSPECTION_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r chaid_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine bins of categorical variables into a smaller number of bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "built_dict = dict.fromkeys(['Mid-Terrace','End-Terrace'],'terraced')\n",
    "built_dict1 = dict.fromkeys(['Semi-Detached','Detached'],'detached')\n",
    "built_dict.update(built_dict1)\n",
    "epc_train['built_form'] = epc_train['BUILT_FORM'].replace(built_dict)\n",
    "epc_test['built_form'] = epc_test['BUILT_FORM'].replace(built_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy_tariff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding which is missing from chaid due to small volumes, and removing null from other groups\n",
    "chaid_dict['ENERGY_TARIFF']['node2'].append('off-peak 18 hour')\n",
    "# chaid_dict['ENERGY_TARIFF']['node1'].remove('Unknown')\n",
    "chaid_dict['ENERGY_TARIFF']['node1'].remove('<missing>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_dict = dict.fromkeys(chaid_dict['ENERGY_TARIFF']['node1'],'single/dual')\n",
    "energy_dict1 = dict.fromkeys(chaid_dict['ENERGY_TARIFF']['node2'],'off-peak')\n",
    "energy_dict['Unknown'] = np.nan \n",
    "energy_dict.update(energy_dict1)\n",
    "epc_train['energy_tariff'] = epc_train['ENERGY_TARIFF'].replace(energy_dict)\n",
    "epc_test['energy_tariff'] = epc_test['ENERGY_TARIFF'].replace(energy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floor description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaid_dict['FLOOR_DESCRIPTION']['node1'].remove('<missing>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_desc_dict = dict.fromkeys(chaid_dict['FLOOR_DESCRIPTION']['node1'],'floor group 1')\n",
    "floor_desc_dict1 = dict.fromkeys(chaid_dict['FLOOR_DESCRIPTION']['node2'],'floor group 2')\n",
    "floor_desc_dict2 = dict.fromkeys(chaid_dict['FLOOR_DESCRIPTION']['node3'],'floor group 3')\n",
    "floor_desc_dict3 = dict.fromkeys(chaid_dict['FLOOR_DESCRIPTION']['node4'],'floor group 4')\n",
    "floor_desc_dict4 = dict.fromkeys(chaid_dict['FLOOR_DESCRIPTION']['node5'],'floor group 5')\n",
    "floor_desc_dict.update(floor_desc_dict1)\n",
    "floor_desc_dict.update(floor_desc_dict2)\n",
    "floor_desc_dict.update(floor_desc_dict3)\n",
    "floor_desc_dict.update(floor_desc_dict4)\n",
    "epc_train['floor_description'] = epc_train['FLOOR_DESCRIPTION'].replace(floor_desc_dict)\n",
    "epc_test['floor_description'] = epc_test['FLOOR_DESCRIPTION'].replace(floor_desc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidying up levels not included in the chaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_desc_dict_extra = dict.fromkeys(['average thermal transmittance 1.4 w/m²k', 'solid',\n",
    "                                       'average thermal transmittance 1.9 w/m²k'],'floor group 2')\n",
    "floor_desc_dict_extra1 = dict.fromkeys(['above unheated space or full exposed'],'floor group 3')\n",
    "floor_desc_dict_extra2 = dict.fromkeys(['average thermal transmittance 2.5 w/m²k','to unheated space'],'floor group 4')\n",
    "floor_desc_dict_extra.update(floor_desc_dict_extra1)\n",
    "floor_desc_dict_extra.update(floor_desc_dict_extra2)\n",
    "epc_train['floor_description'] = epc_train['floor_description'].replace(floor_desc_dict_extra)\n",
    "epc_test['floor_description'] = epc_test['floor_description'].replace(floor_desc_dict_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floor Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_level_dict = dict.fromkeys(['Ground','ground floor','Basement',],'ground floor')\n",
    "floor_level_dict1 = dict.fromkeys(['1st','2nd','3rd','4th'],'low floors')\n",
    "floor_level_dict2 = dict.fromkeys(['mid floor','5th','6th','7th','8th','9th','10th','11th'],'mid floors')\n",
    "floor_level_dict3 = dict.fromkeys(['top floor','12th','13th','14th','15th','16th','17th','18th','19th','20th',\n",
    "                                   '21st or above'],'mid floors')\n",
    "floor_level_dict.update(floor_level_dict1)\n",
    "floor_level_dict.update(floor_level_dict2)\n",
    "floor_level_dict.update(floor_level_dict3)\n",
    "epc_train['floor_level'] = epc_train['FLOOR_LEVEL'].replace(floor_level_dict)\n",
    "epc_test['floor_level'] = epc_test['FLOOR_LEVEL'].replace(floor_level_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glazed Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "glazed_dict = dict.fromkeys(['double glazing installed before 2002','double glazing, unknown install date'],'old double glazing')\n",
    "glazed_dict1 = dict.fromkeys(['triple, known data','triple glazing'],'triple glazing')\n",
    "glazed_dict2 = dict.fromkeys(['secondary glazing','not defined','single glazing'],'old glazing')\n",
    "glazed_dict3 = dict.fromkeys(['double, known data','double glazing installed during or after 2002'],'double glazing')\n",
    "glazed_dict.update(glazed_dict1)\n",
    "glazed_dict.update(glazed_dict2)\n",
    "glazed_dict.update(glazed_dict3)\n",
    "glazed_dict['INVALID!'] = np.nan\n",
    "epc_train['glazed_type'] = epc_train['GLAZED_TYPE'].replace(glazed_dict)\n",
    "epc_test['glazed_type'] = epc_test['GLAZED_TYPE'].replace(glazed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hot water description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_water_dict = dict.fromkeys(chaid_dict['HOTWATER_DESCRIPTION']['node1'],'water group 1')\n",
    "hot_water_dict1 = dict.fromkeys(chaid_dict['HOTWATER_DESCRIPTION']['node2'],'water group 2')\n",
    "hot_water_dict.update(hot_water_dict1)\n",
    "epc_train['hotwater_description'] = epc_train['HOTWATER_DESCRIPTION'].replace(hot_water_dict)\n",
    "epc_test['hotwater_description'] = epc_test['HOTWATER_DESCRIPTION'].replace(hot_water_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_dict_extra = dict.fromkeys(['7-hour tariff (on-peak)',\n",
    "                                  'From community scheme, plus solar',\n",
    "                                  'From main system, 7-hour tariff (on-peak)',\n",
    "                                  'Solid fuel range cooker, plus solar, no cylinder thermostat',\n",
    "                                  'Gas boiler/circulator, plus solar, no cylinder thermostat',\n",
    "                                  'Electric immersion, standard tariff, plus solar, waste water heat recovery',\n",
    "                                  'Solid fuel boiler/circulator, plus solar','Community scheme with CHP',\n",
    "                                  'Oil boiler/circulator, waste water heat recovery',\n",
    "                                  'From secondary system, no cylinder thermostat, plus solar',\n",
    "                                  'From secondary system, no cylinderstat, plus solar',\n",
    "                                  'From second main heating system, plus solar', 'Gas range cooker, plus solar',\n",
    "                                  'Gas range cooker, plus solar, no cylinder thermostat',\n",
    "                                  'Heat pump, waste water heat recovery','SAP:Hot-Water',\n",
    "                                  'From main system, no cylinder thermostat, flue gas heat recovery'\n",
    "                                 ],'water group 1')\n",
    "water_dict_extra1 = dict.fromkeys(['O system eilaidd','Room heaters, anthracite',\n",
    "                                   'Oil range cooker, plus solar',\n",
    "                                   'Oil range cooker, plus solar, no cylinder thermostat',\n",
    "                                   'From main system, no cylinderstat, no cylinderstat',\n",
    "                                   'No system present : electric immersion assumed', 'Electric immersion',\n",
    "                                   'From secondary heater, standard tariff','From secondary heater',\n",
    "                                   'No system present?electric immersion assumed', ', no cylinderstat',\n",
    "                                   'Single-point gas water heater', 'Point gas water heater, no cylinderstat',\n",
    "                                   'Back boiler (hot water only), gas','Gas multipoint, no cylinder thermostat',\n",
    "                                   'Electric instantaneous at point of use, no cylinder thermostat',\n",
    "                                   'No hot water system present - electric immersion assumed, plus solar',\n",
    "                                   'No system present: electric immersion assumed, no cylinder thermostat',\n",
    "                                   'Solid fuel range cooker, no cylinderstat','Gas boiler/circulator, no cylinderstat'\n",
    "                                 ],'water group 2')\n",
    "water_dict_extra.update(water_dict_extra1)\n",
    "epc_train['hotwater_description'] = epc_train['hotwater_description'].replace(water_dict_extra)\n",
    "epc_test['hotwater_description'] = epc_test['hotwater_description'].replace(water_dict_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting remaining small options into one group, note leaving 'From main system' separate as it's 75% of all values\n",
    "hotwater_leftover = [x for x in set(epc_train['hotwater_description']) if 'water group' not in str(x)]\n",
    "hotwater_leftover_test = [x for x in set(epc_test['hotwater_description']) if 'water group' not in str(x)]\n",
    "#hotwater_leftover.remove('From main system')\n",
    "#hotwater_leftover_test.remove('From main system')\n",
    "hotwater_leftover.extend(hotwater_leftover_test)\n",
    "hotwater_leftover_dict = dict.fromkeys(hotwater_leftover,'water group 3')\n",
    "epc_train['hotwater_description'] = epc_train['hotwater_description'].replace(hotwater_leftover_dict)\n",
    "epc_test['hotwater_description'] = epc_test['hotwater_description'].replace(hotwater_leftover_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Lighting Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_train[['low_energy_lighting_perc']] = epc_train.apply(lambda row: 100.0 if row['LIGHTING_DESCRIPTION'] == 'low energy lighting in all fixed outlets' else row['low_energy_lighting_perc'], axis=1)\n",
    "epc_train[['low_energy_lighting_perc']] = epc_train.apply(lambda row: 0 if row['LIGHTING_DESCRIPTION'] == 'no low energy lighting' else row['low_energy_lighting_perc'], axis=1)\n",
    "epc_test[['low_energy_lighting_perc']] = epc_test.apply(lambda row: 100.0 if row['LIGHTING_DESCRIPTION'] == 'low energy lighting in all fixed outlets' else row['low_energy_lighting_perc'], axis=1)\n",
    "epc_test[['low_energy_lighting_perc']] = epc_test.apply(lambda row: 0 if row['LIGHTING_DESCRIPTION'] == 'no low energy lighting' else row['low_energy_lighting_perc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaid_dict['LIGHTING_DESCRIPTION']['node1'].remove('<missing>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lighting_dict = dict.fromkeys(chaid_dict['LIGHTING_DESCRIPTION']['node1'],'lighting group 1')\n",
    "lighting_dict1 = dict.fromkeys(chaid_dict['LIGHTING_DESCRIPTION']['node2'],'lighting group 2')\n",
    "lighting_dict2 = dict.fromkeys(chaid_dict['LIGHTING_DESCRIPTION']['node3'],'lighting group 3')\n",
    "lighting_dict.update(lighting_dict1)\n",
    "lighting_dict.update(lighting_dict2)\n",
    "epc_train['lighting_description'] = epc_train['LIGHTING_DESCRIPTION'].replace(lighting_dict)\n",
    "epc_test['lighting_description'] = epc_test['LIGHTING_DESCRIPTION'].replace(lighting_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main heating controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaid_dict['MAIN_HEATING_CONTROLS']['node1'].remove('<missing>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_heat_dict = dict.fromkeys(chaid_dict['MAIN_HEATING_CONTROLS']['node1'],'main heating controls group 1')\n",
    "main_heat_dict1 = dict.fromkeys(chaid_dict['MAIN_HEATING_CONTROLS']['node2'],'main heating controls group 2')\n",
    "main_heat_dict2 = dict.fromkeys(chaid_dict['MAIN_HEATING_CONTROLS']['node3'],'main heating controls group 3')\n",
    "main_heat_dict3 = dict.fromkeys(chaid_dict['MAIN_HEATING_CONTROLS']['node4'],'main heating controls group 4')\n",
    "main_heat_dict4 = dict.fromkeys(chaid_dict['MAIN_HEATING_CONTROLS']['node5'],'main heating controls group 5')\n",
    "main_heat_dict.update(main_heat_dict1)\n",
    "main_heat_dict.update(main_heat_dict2)\n",
    "main_heat_dict.update(main_heat_dict3)\n",
    "main_heat_dict.update(main_heat_dict4)\n",
    "epc_train['mainheat_controls'] = epc_train['MAIN_HEATING_CONTROLS'].replace(main_heat_dict)\n",
    "epc_test['mainheat_controls'] = epc_test['MAIN_HEATING_CONTROLS'].replace(main_heat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_heat_dict_extra = dict.fromkeys(['Charging system linked to use of communit heating, TRVs'\n",
    "                                     ],'main heating controls group 3')\n",
    "main_heat_dict_extra1 = dict.fromkeys([\"Thermostat ystafell yn unig\"],'main heating controls group 2')\n",
    "main_heat_dict_extra2 = dict.fromkeys([\"Rhaglennydd ac o leiaf ddau thermostat ystafell\",\n",
    "                                       'Rheoli gwefr drydanol yn awtomatig',\n",
    "                                       'Programmer + appliance thermostats',\n",
    "                                       'Rhaglennydd a thermostatau ar y cyfarpar',\n",
    "                                       'Programmer + TRVs + boiler energy manager',\n",
    "                                       'Programmer + TRVs + flow switch',\n",
    "                                       'Programmer + room thermostats'\n",
    "                                      ],'main heating controls group 4')\n",
    "main_heat_dict_extra3 = dict.fromkeys(['Charging system linked to use of communit heating, programmer and TRVs',\n",
    "                                       'Programmer and delayed start thermostat'\n",
    "                                      ],'main heating controls group 1')\n",
    "main_heat_dict_extra.update(main_heat_dict_extra1)\n",
    "main_heat_dict_extra.update(main_heat_dict_extra2)\n",
    "main_heat_dict_extra.update(main_heat_dict_extra3)\n",
    "epc_train['mainheat_controls'] = epc_train['mainheat_controls'].replace(main_heat_dict_extra)\n",
    "epc_test['mainheat_controls'] = epc_test['mainheat_controls'].replace(main_heat_dict_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_type_dict = dict.fromkeys(['Bungalow','Park home'],'one storey building')\n",
    "epc_train['property_type'] = epc_train['PROPERTY_TYPE'].replace(prop_type_dict)\n",
    "epc_test['property_type'] = epc_test['PROPERTY_TYPE'].replace(prop_type_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roof description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaid_dict['ROOF_DESCRIPTION']['node1'].remove('<missing>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "roof_dict = dict.fromkeys(chaid_dict['ROOF_DESCRIPTION']['node1'],'roof group 1')\n",
    "roof_dict1 = dict.fromkeys(chaid_dict['ROOF_DESCRIPTION']['node2'],'roof group 2')\n",
    "roof_dict2 = dict.fromkeys(chaid_dict['ROOF_DESCRIPTION']['node3'],'roof group 3')\n",
    "roof_dict3 = dict.fromkeys(chaid_dict['ROOF_DESCRIPTION']['node4'],'roof group 4')\n",
    "roof_dict4 = dict.fromkeys(chaid_dict['ROOF_DESCRIPTION']['node5'],'roof group 5')\n",
    "roof_dict5 = dict.fromkeys(chaid_dict['ROOF_DESCRIPTION']['node6'],'roof group 6')\n",
    "roof_dict.update(roof_dict1)\n",
    "roof_dict.update(roof_dict2)\n",
    "roof_dict.update(roof_dict3)\n",
    "roof_dict.update(roof_dict4)\n",
    "roof_dict.update(roof_dict5)\n",
    "epc_train['roof_description'] = epc_train['ROOF_DESCRIPTION'].replace(roof_dict)\n",
    "epc_test['roof_description'] = epc_test['ROOF_DESCRIPTION'].replace(roof_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting remaining small options into one group, note leaving 'From main system' separate as it's 75% of all values\n",
    "roof_leftover = [x for x in set(epc_train['roof_description']) if 'roof group' not in str(x)]\n",
    "roof_leftover_test = [x for x in set(epc_test['roof_description']) if 'roof group' not in str(x)]\n",
    "roof_leftover.extend(roof_leftover_test)\n",
    "roof_leftover_dict = dict.fromkeys(roof_leftover,'roof group 7')\n",
    "epc_train['roof_description'] = epc_train['roof_description'].replace(roof_leftover_dict)\n",
    "epc_test['roof_description'] = epc_test['roof_description'].replace(roof_leftover_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaid_dict['TRANSACTION_TYPE']['node1'].remove('<missing>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dict = dict.fromkeys(chaid_dict['TRANSACTION_TYPE']['node1'],'private rental and sale')\n",
    "trans_dict1 = dict.fromkeys(chaid_dict['TRANSACTION_TYPE']['node2'],'social rental and new build')\n",
    "trans_dict2 = dict.fromkeys(chaid_dict['TRANSACTION_TYPE']['node3'],'private rental and sale')\n",
    "trans_dict3 = dict.fromkeys(chaid_dict['TRANSACTION_TYPE']['node4'],'social rental and new build')\n",
    "#trans_dict4 = dict.fromkeys(chaid_dict['TRANSACTION_TYPE']['node5'],'assessment')\n",
    "trans_dict.update(trans_dict1)\n",
    "trans_dict.update(trans_dict2)\n",
    "trans_dict.update(trans_dict3)\n",
    "#trans_dict.update(trans_dict4)\n",
    "trans_dict['unknown'] = np.nan\n",
    "epc_train['transaction_type'] = epc_train['TRANSACTION_TYPE'].replace(trans_dict)\n",
    "epc_test['transaction_type'] = epc_test['TRANSACTION_TYPE'].replace(trans_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walls description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaid_dict['WALLS_DESCRIPTION']['node1'].remove('<missing>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "walls_dict = dict.fromkeys(chaid_dict['WALLS_DESCRIPTION']['node1'],'walls group 1')\n",
    "walls_dict1 = dict.fromkeys(chaid_dict['WALLS_DESCRIPTION']['node2'],'walls group 2')\n",
    "walls_dict2 = dict.fromkeys(chaid_dict['WALLS_DESCRIPTION']['node3'],'walls group 3')\n",
    "walls_dict3 = dict.fromkeys(chaid_dict['WALLS_DESCRIPTION']['node4'],'walls group 4')\n",
    "walls_dict4 = dict.fromkeys(chaid_dict['WALLS_DESCRIPTION']['node5'],'walls group 5')\n",
    "walls_dict.update(walls_dict1)\n",
    "walls_dict.update(walls_dict2)\n",
    "walls_dict.update(walls_dict3)\n",
    "walls_dict.update(walls_dict4)\n",
    "epc_train['walls_description'] = epc_train['WALLS_DESCRIPTION'].replace(walls_dict)\n",
    "epc_test['walls_description'] = epc_test['WALLS_DESCRIPTION'].replace(walls_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting remaining small options into one group, note leaving 'From main system' separate as it's 75% of all values\n",
    "walls_leftover = [x for x in set(epc_train['walls_description']) if 'walls group' not in str(x)]\n",
    "walls_leftover_test = [x for x in set(epc_test['walls_description']) if 'walls group' not in str(x)]\n",
    "walls_leftover.extend(walls_leftover_test)\n",
    "walls_leftover_dict = dict.fromkeys(walls_leftover,'walls group 6')\n",
    "epc_train['walls_description'] = epc_train['walls_description'].replace(walls_leftover_dict)\n",
    "epc_test['walls_description'] = epc_test['walls_description'].replace(walls_leftover_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windows Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_dict = dict.fromkeys(chaid_dict['WINDOWS_DESCRIPTION']['node1'],'window group 1')\n",
    "windows_dict1 = dict.fromkeys(chaid_dict['WINDOWS_DESCRIPTION']['node2'],'window group 2')\n",
    "windows_dict2 = dict.fromkeys(chaid_dict['WINDOWS_DESCRIPTION']['node3'],'window group 3')\n",
    "windows_dict.update(windows_dict1)\n",
    "windows_dict.update(windows_dict2)\n",
    "epc_train['window_description'] = epc_train['WINDOWS_DESCRIPTION'].replace(windows_dict)\n",
    "epc_test['window_description'] = epc_test['WINDOWS_DESCRIPTION'].replace(windows_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_train['window_description'] = epc_train['window_description'].replace('multiple glazing throughout double glazing','window group 3')\n",
    "epc_test['window_description'] = epc_test['window_description'].replace('multiple glazing throughout double glazing','window group 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_dict = dict.fromkeys(['Blaenau Gwent','Neath Port Talbot','Pembrokeshire','Rhondda Cynon Taf','Caerphilly',\n",
    "                             'Flintshire','Carmarthenshire','Powys','Conwy','Ceredigion','Debighshire',\n",
    "                             'Gwynedd','Isle of Anglesey'],'rural')\n",
    "region_dict1 = dict.fromkeys(['Bridgend','Monmouthshire','Wrexham','Merthyr Tydfil','Vale of Glamorgan','Cardiff',\n",
    "                              'Torfaen','Newport','Swansea'],'suburban')\n",
    "region_dict.update(region_dict1)\n",
    "epc_train['locality'] = epc_train['region'].replace(region_dict)\n",
    "epc_test['locality'] = epc_test['region'].replace(region_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning Numeric Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberic_bins(var,bin_boundaries,bin_labels):\n",
    "\n",
    "  var_new = pd.cut(var,bins = bin_boundaries,labels = bin_labels)\n",
    "\n",
    "  return var_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension_max = epc_train['EXTENSION_COUNT'].max()\n",
    "extension_bins = [-1,0,1,extension_max]\n",
    "extension_labels = ['0','1','2+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_train['extension'] = numberic_bins(epc_train['EXTENSION_COUNT'],extension_bins,extension_labels)\n",
    "epc_test['extension'] = numberic_bins(epc_test['EXTENSION_COUNT'],extension_bins,extension_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floor height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_max = epc_train['FLOOR_HEIGHT'].max()\n",
    "floor_bins = [0,2.3,2.4,2.4999,2.5,2.7,floor_max]\n",
    "floor_labels = ['0-2.3','2.3-2.4','2.4-2.5','2.5','2.5-2.7','2.7+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_train['floor_height'] = numberic_bins(epc_train['FLOOR_HEIGHT'],floor_bins,floor_labels)\n",
    "epc_test['floor_height'] = numberic_bins(epc_test['FLOOR_HEIGHT'],floor_bins,floor_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of habitable rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_max = epc_train['NUMBER_HABITABLE_ROOMS'].max()\n",
    "room_bins = [0,1,2,3,4,5,room_max]\n",
    "room_labels = ['1','2','3','4','5','6+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_train['habitable_rooms'] = numberic_bins(epc_train['NUMBER_HABITABLE_ROOMS'],room_bins,room_labels)\n",
    "epc_test['habitable_rooms'] = numberic_bins(epc_test['NUMBER_HABITABLE_ROOMS'],room_bins,room_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of open fireplaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_max = epc_train['NUMBER_OPEN_FIREPLACES'].max()\n",
    "fire_bins = [-1,0,1,fire_max]\n",
    "fire_labels = ['0','1','2+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_train['open_fireplaces'] = numberic_bins(epc_train['NUMBER_OPEN_FIREPLACES'],fire_bins,fire_labels)\n",
    "epc_test['open_fireplaces'] = numberic_bins(epc_test['NUMBER_OPEN_FIREPLACES'],fire_bins,fire_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features that correlate with each other or are leading\n",
    "correlated_variables = ['CO2_EMISS_CURR_PER_FLOOR_AREA','CO2_EMISSIONS_CURRENT','ENERGY_CONSUMPTION_CURRENT',\n",
    "                     'HEATING_COST_CURRENT','HOT_WATER_COST_CURRENT','HOT_WATER_ENERGY_EFF','HOT_WATER_ENV_EFF',\n",
    "                     'LIGHTING_COST_CURRENT','LIGHTING_ENERGY_EFF','LIGHTING_ENV_EFF','LMK_KEY','LOW_ENERGY_LIGHTING',\n",
    "                     'MAIN_FUEL','MAINHEAT_ENERGY_EFF','MAINHEAT_ENV_EFF','MAINHEATC_ENERGY_EFF','MAINHEATC_ENV_EFF',\n",
    "                     'MAINHEATCONT_DESCRIPTION','MECHANICAL_VENTILATION','MULTI_GLAZE_PROPORTION','NUMBER_HEATED_ROOMS',\n",
    "                     'POSTCODE','ROOF_ENERGY_EFF','ROOF_ENV_EFF','SECONDHEAT_DESCRIPTION','WALLS_ENERGY_EFF',\n",
    "                     'WALLS_ENV_EFF','WINDOWS_ENERGY_EFF','WINDOWS_ENV_EFF']\n",
    "\n",
    "# features replace with binned features\n",
    "replace_features = ['region','CURRENT_ENERGY_RATING','PROPERTY_TYPE','BUILT_FORM','INSPECTION_DATE','TRANSACTION_TYPE',\n",
    "                   'ENERGY_TARIFF','FLOOR_LEVEL','GLAZED_TYPE','EXTENSION_COUNT','NUMBER_HABITABLE_ROOMS',\n",
    "                    'NUMBER_OPEN_FIREPLACES','HOTWATER_DESCRIPTION','FLOOR_DESCRIPTION','MAIN_HEATING_CONTROLS',\n",
    "                    'WINDOWS_DESCRIPTION','WALLS_DESCRIPTION','ROOF_DESCRIPTION','LIGHTING_DESCRIPTION',\n",
    "                    'FLOOR_HEIGHT']\n",
    "\n",
    "# other fields not needed\n",
    "fields_to_drop = ['floors_average_thermal_transmittance','low_energy_lighting_perc','LODGEMENT_DATE',\n",
    "                  'roof_average_thermal_transmittance','walls_average_thermal_transmittance'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_train.drop(correlated_variables,axis = 1,inplace=True)\n",
    "epc_train.drop(replace_features,axis = 1,inplace=True)\n",
    "epc_train.drop(fields_to_drop,axis = 1,inplace=True)\n",
    "epc_test.drop(correlated_variables,axis = 1,inplace=True)\n",
    "epc_test.drop(replace_features,axis = 1,inplace=True)\n",
    "epc_test.drop(fields_to_drop,axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_train.to_csv(os.path.join(processing_path,epc_train_data_fname),index = False)\n",
    "epc_test.to_csv(os.path.join(processing_path,epc_test_data_fname),index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
