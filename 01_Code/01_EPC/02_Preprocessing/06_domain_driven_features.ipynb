{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Driven Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EPC data contains several categorical variables with a lot of values. In order to find suitable features which will retain the most information, three feature sets are explored; \n",
    "* data driven \n",
    "* domain driven \n",
    "* exhaustive \n",
    "\n",
    "The domain-driven approach groups categories together using expert domain-based knowledge. Examples of this are grouping the original fields such as rural, urban and suburban local authorities together, or pulling out the key features such as ‘pitched roof’ or ‘insulated floor’. It should be noted that although the domain-driven features are easier to understand, this approach will not be as powerful as the data-driven approach, as performance has been traded for interpretation.\n",
    "\n",
    "This script groups the levels of the categorical fields and bins the numerical fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables from config file\n",
    "config_path = os.path.abspath('..')[:-7]\n",
    "\n",
    "with open(config_path + '/config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "processing_path = config['DEFAULT']['processing_path']\n",
    "epc_train_clean_fname = config['DEFAULT']['epc_train_clean_fname']\n",
    "epc_test_clean_fname = config['DEFAULT']['epc_test_clean_fname']\n",
    "epc_train_do_fname = config['DEFAULT']['epc_train_domain_fname']\n",
    "epc_test_do_fname = config['DEFAULT']['epc_test_domain_fname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {'INSPECTION_DATE':'str'}\n",
    "\n",
    "epc_train = pd.read_csv(os.path.join(processing_path,epc_train_clean_fname),header = 0,delimiter = ',',dtype = dtype_dict,\n",
    "                        parse_dates = ['INSPECTION_DATE'])\n",
    "epc_test = pd.read_csv(os.path.join(processing_path,epc_test_clean_fname),header = 0,delimiter = ',',dtype = dtype_dict,\n",
    "                        parse_dates = ['INSPECTION_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r chaid_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating fields relating to insulation across all relevant variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Thermal_transmittance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def att_fields(df):\n",
    "\n",
    "    # finds the decimal number\n",
    "    df['floors_att'] = df['FLOOR_DESCRIPTION'].str.findall(r'\\d.\\d*')\n",
    "    df['floors_att'] = df['floors_att'].str[0].astype(float)\n",
    "    # classifies average thermal transmittance\n",
    "    df['floors_att_good'] = df.apply(lambda row: 1 if row['floors_att'] <= 0.2 and 'mm ' not in str(row['FLOOR_DESCRIPTION']) else 0,axis = 1)\n",
    "    df['floors_att_poor'] = df.apply(lambda row: 1 if row['floors_att'] >= 1 and 'mm ' not in str(row['FLOOR_DESCRIPTION']) else 0,axis = 1)\n",
    "\n",
    "    df['walls_att'] = df['WALLS_DESCRIPTION'].str.findall(r'\\d.\\d*')\n",
    "    df['walls_att'] = df['walls_att'].str[0].astype(float)\n",
    "\n",
    "    df['walls_att_good'] = df.apply(lambda row: 1 if row['walls_att'] <= 0.25 else 0,axis = 1)\n",
    "    df['walls_att_poor'] = df.apply(lambda row: 1 if row['walls_att'] >= 1.5 else 0,axis = 1)\n",
    "\n",
    "    df['roof_att'] = df['ROOF_DESCRIPTION'].str.findall(r'\\d.\\d')\n",
    "    df['roof_att'] = df['roof_att'].str[0].astype(float)\n",
    "\n",
    "    df['roof_att_good'] = df.apply(lambda row: 1 if row['roof_att'] <= 0.15 and 'mm ' not in str(row['ROOF_DESCRIPTION']) else 0,axis = 1)\n",
    "    df['roof_att_poor'] = df.apply(lambda row: 1 if row['roof_att'] >= 1 and 'mm ' not in str(row['ROOF_DESCRIPTION']) else 0,axis = 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_train = att_fields(epc_train)\n",
    "epc_test = att_fields(epc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all descriptions from variables related to insulation\n",
    "roof_descriptions = set(epc_train['ROOF_DESCRIPTION']).union(set(epc_test['ROOF_DESCRIPTION']))\n",
    "floor_descriptions = set(epc_train['FLOOR_DESCRIPTION']).union(set(epc_test['FLOOR_DESCRIPTION']))\n",
    "wall_descriptions = set(epc_train['WALLS_DESCRIPTION']).union(set(epc_test['WALLS_DESCRIPTION']))\n",
    "\n",
    "all_descriptions = roof_descriptions.union(floor_descriptions)\n",
    "all_descriptions = all_descriptions.union(wall_descriptions)\n",
    "\n",
    "# separate list of descriptions indicating partial insulation\n",
    "partial_insulation_desc1 = [x for x in all_descriptions if 'limited insulation' in str(x)]\n",
    "partial_insulation_desc2 = [x for x in all_descriptions if 'partial insulation' in str(x)]\n",
    "partial_insulation_desc3 = [x for x in all_descriptions if 'insulated' in str(x) and 'no insulation' in str(x)]\n",
    "partial_insulation_desc4 = [x for x in all_descriptions if 'insulated' in str(x) and '0mm insulation' in str(x)]\n",
    "\n",
    "partial_insulation_desc = set(partial_insulation_desc1 + partial_insulation_desc2 + partial_insulation_desc3)\n",
    "\n",
    "# separate list of descriptions indicating complete insulation\n",
    "insulated_desc1 = [x for x in all_descriptions if 'loft insulation' in str(x)]\n",
    "insulated_desc2 = [x for x in all_descriptions if 'mm insulation' in str(x) and '0mm insulation' not in str(x)]\n",
    "insulated_desc3 = [x for x in all_descriptions if 'insulated' in str(x) and 'no insulation' not in str(x)]\n",
    "\n",
    "insulated_desc = set(insulated_desc1 + insulated_desc2 + insulated_desc3)\n",
    "\n",
    "# all other descriptions which likely related to no insulation \n",
    "no_insulation_desc = [x for x in all_descriptions if x not in partial_insulation_desc and x not in insulated_desc]\n",
    "\n",
    "# dictionary of insulation terms to be used in replace\n",
    "insulation_dict = dict.fromkeys(partial_insulation_desc,'partial insulation')\n",
    "insulation_dict2 = dict.fromkeys(insulated_desc,'insulated')\n",
    "insulation_dict3 = dict.fromkeys(no_insulation_desc,'no insulation')\n",
    "insulation_dict.update(insulation_dict2)\n",
    "insulation_dict.update(insulation_dict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_train['wall_insulation'] = epc_train['WALLS_DESCRIPTION'].replace(insulation_dict)\n",
    "epc_test['wall_insulation'] = epc_test['WALLS_DESCRIPTION'].replace(insulation_dict)\n",
    "\n",
    "epc_train['floor_insulation'] = epc_train['FLOOR_DESCRIPTION'].replace(insulation_dict)\n",
    "epc_test['floor_insulation'] = epc_test['FLOOR_DESCRIPTION'].replace(insulation_dict)\n",
    "\n",
    "epc_train['roof_insulation'] = epc_train['ROOF_DESCRIPTION'].replace(insulation_dict)\n",
    "epc_test['roof_insulation'] = epc_test['ROOF_DESCRIPTION'].replace(insulation_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining att fields and insulation fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_train['wall_insul'] = epc_train.apply(lambda row: 'insulated' if row['walls_att_good'] == 1 else row['wall_insulation'], axis=1)\n",
    "epc_train['floor_insul'] = epc_train.apply(lambda row: 'insulated' if row['floors_att_good'] == 1 else row['floor_insulation'], axis=1)\n",
    "epc_train['roof_insul'] = epc_train.apply(lambda row: 'insulated' if row['roof_att_good'] == 1 else row['roof_insulation'], axis=1)\n",
    "\n",
    "epc_test['wall_insul'] = epc_test.apply(lambda row: 'insulated' if row['walls_att_good'] == 1 else row['wall_insulation'], axis=1)\n",
    "epc_test['floor_insul'] = epc_test.apply(lambda row: 'insulated' if row['floors_att_good'] == 1 else row['floor_insulation'], axis=1)\n",
    "epc_test['roof_insul'] = epc_test.apply(lambda row: 'insulated' if row['roof_att_good'] == 1 else row['roof_insulation'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived fields from roof type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roof_types(df):\n",
    "\n",
    "    df['pitched_roof'] = df.apply(lambda row: 1 if 'pitched' in str(row['ROOF_DESCRIPTION']).lower() else 0,axis = 1)\n",
    "    df['flat_roof'] = df.apply(lambda row: 1 if 'flat' in str(row['ROOF_DESCRIPTION']).lower() else 0,axis = 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "epc_train = roof_types(epc_train)\n",
    "epc_test = roof_types(epc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived fields from wall type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wall_types(df):\n",
    "\n",
    "    df['cavity_wall'] = df.apply(lambda row: 1 if 'cavity wall' in str(row['WALLS_DESCRIPTION']).lower() else 0,axis = 1)\n",
    "    df['granite_wall'] = df.apply(lambda row: 1 if 'granite or whinstone' in str(row['WALLS_DESCRIPTION']).lower() else 0,axis = 1)\n",
    "    df['timber_wall'] = df.apply(lambda row: 1 if 'timber frame' in str(row['WALLS_DESCRIPTION']).lower() else 0,axis = 1)\n",
    "    df['sandstone_wall'] = df.apply(lambda row: 1 if 'sandstone' in str(row['WALLS_DESCRIPTION']).lower() else 0,axis = 1)\n",
    "    df['brick_wall'] = df.apply(lambda row: 1 if 'solid brick' in str(row['WALLS_DESCRIPTION']).lower() else 0,axis = 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "epc_train = wall_types(epc_train)\n",
    "epc_test = wall_types(epc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived fields from floor type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floor_types(df):\n",
    "\n",
    "    df['solid_floor'] = df.apply(lambda row: 1 if 'solid' in str(row['FLOOR_DESCRIPTION']).lower() else 0,axis = 1)\n",
    "    df['suspended_floor'] = df.apply(lambda row: 1 if 'suspended' in str(row['FLOOR_DESCRIPTION']).lower() else 0,axis = 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "epc_train = floor_types(epc_train)\n",
    "epc_test = floor_types(epc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived fields from hotwater types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hotwater_types(df):\n",
    "\n",
    "    df['hotwater_mains'] = df.apply(lambda row: 1 if 'from main system' in str(row['HOTWATER_DESCRIPTION']).lower() else 0,axis = 1)\n",
    "    df['hotwater_immersion'] = df.apply(lambda row: 1 if 'immersion' in str(row['HOTWATER_DESCRIPTION']).lower() else 0,axis = 1)\n",
    "    df['hotwater_commmunity'] = df.apply(lambda row: 1 if 'community' in str(row['HOTWATER_DESCRIPTION']).lower() else 0,axis = 1)\n",
    "    df['hotwater_solar'] = df.apply(lambda row: 1 if 'solar' in str(row['HOTWATER_DESCRIPTION']).lower() else 0,axis = 1)\n",
    "    df['hotwater_gas'] = df.apply(lambda row: 1 if 'gas' in str(row['HOTWATER_DESCRIPTION']).lower() else 0,axis = 1)\n",
    "    df['hotwater_recovery'] = df.apply(lambda row: 1 if 'recovery' in str(row['HOTWATER_DESCRIPTION']).lower() else 0,axis = 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "epc_train = hotwater_types(epc_train)\n",
    "epc_test = hotwater_types(epc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived fields from window description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window description\n",
    "window_dict = dict.fromkeys(['full double glazing','full triple glazing',\n",
    "                             'high performance glazing','multiple glazing throughout','double glazing',\n",
    "                             'multiple glazing throughout double glazing'],1)\n",
    "\n",
    "window_dict2 = dict.fromkeys(['partial double glazing','mostly double glazing',\n",
    "                              'some double glazing','single glazing and double glazing','mostly multiple glazing',\n",
    "                              'partial multiple glazing','single and multiple glazing','mostly triple glazing',\n",
    "                              'some multiple glazing','partial triple glazing','some triple glazing'],1)\n",
    "\n",
    "window_dict3 = dict.fromkeys(['full secondary glazing','partial secondary glazing',\n",
    "                              'mostly secondary glazing','some secondary glazing','secondary glazing',\n",
    "                              'single glazing and secondary glazing'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_types(df):\n",
    "    df['window_multiple'] = df['WINDOWS_DESCRIPTION'].map(window_dict)\n",
    "    df['window_partial_multiple'] = df['WINDOWS_DESCRIPTION'].map(window_dict2)\n",
    "    df['window_secondary'] = df['WINDOWS_DESCRIPTION'].map(window_dict3)\n",
    "    \n",
    "    df = df.fillna({'window_partial_multiple':0,'window_secondary':0,'window_multiple':0})\n",
    "    \n",
    "    df['window_partial_multiple'] = df['window_partial_multiple'].astype(int)\n",
    "    df['window_secondary'] = df['window_secondary'].astype(int)\n",
    "    df['window_multiple'] = df['window_multiple'].astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "epc_train = window_types(epc_train)\n",
    "epc_test = window_types(epc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived fields from heating control types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat_control_types(df):\n",
    "\n",
    "    df['heat_control_programmer'] = df.apply(lambda row: 1 if 'programmer' in str(row['MAIN_HEATING_CONTROLS']).lower() else 0,axis = 1)\n",
    "    df['heat_control_trv'] = df.apply(lambda row: 1 if 'trvs' in str(row['MAIN_HEATING_CONTROLS']).lower() else 0,axis = 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "epc_train = heat_control_types(epc_train)\n",
    "epc_test = heat_control_types(epc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of descriptions indicating room thermostats\n",
    "\n",
    "heating_control_list = set(epc_train['MAIN_HEATING_CONTROLS']).union(set(epc_test['MAIN_HEATING_CONTROLS']))\n",
    "\n",
    "room_thermostat = [x for x in heating_control_list if 'thermostat' in str(x) \n",
    "                   and 'no room thermostat' not in str(x) and 'no thermostat' not in str(x) \n",
    "                   and 'appliance thermostat' not in str(x)]\n",
    "room_thermostat.remove('no time or thermostat control of room temperature')\n",
    "\n",
    "# all other descriptions which likely related to no thermostat\n",
    "no_thermostat_desc = [x for x in heating_control_list if x not in room_thermostat]\n",
    "\n",
    "room_thermostat_dict = dict.fromkeys(room_thermostat,1)\n",
    "no_thermostat_dict = dict.fromkeys(no_thermostat_desc,0)\n",
    "\n",
    "room_thermostat_dict.update(no_thermostat_dict)\n",
    "\n",
    "epc_train['heat_control_room_thermostat'] = epc_train['MAIN_HEATING_CONTROLS'].replace(room_thermostat_dict)\n",
    "epc_test['heat_control_room_thermostat'] = epc_test['MAIN_HEATING_CONTROLS'].replace(room_thermostat_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other features as data driven approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "built_dict = dict.fromkeys(['Mid-Terrace','End-Terrace'],'terraced')\n",
    "built_dict1 = dict.fromkeys(['Semi-Detached','Detached'],'detached')\n",
    "built_dict.update(built_dict1)\n",
    "epc_train['built_form'] = epc_train['BUILT_FORM'].replace(built_dict)\n",
    "epc_test['built_form'] = epc_test['BUILT_FORM'].replace(built_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy Tariff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding which is missing from chaid due to small volumes, and removing null from other groups\n",
    "chaid_dict['ENERGY_TARIFF']['node2'].append('off-peak 18 hour')\n",
    "# chaid_dict['ENERGY_TARIFF']['node1'].remove('Unknown')\n",
    "chaid_dict['ENERGY_TARIFF']['node1'].remove('<missing>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_dict = dict.fromkeys(chaid_dict['ENERGY_TARIFF']['node1'],'single/dual')\n",
    "energy_dict1 = dict.fromkeys(chaid_dict['ENERGY_TARIFF']['node2'],'off-peak')\n",
    "energy_dict['Unknown'] = np.nan \n",
    "energy_dict.update(energy_dict1)\n",
    "epc_train['energy_tariff'] = epc_train['ENERGY_TARIFF'].replace(energy_dict)\n",
    "epc_test['energy_tariff'] = epc_test['ENERGY_TARIFF'].replace(energy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floor Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_level_dict = dict.fromkeys(['Ground','ground floor','Basement',],'ground floor')\n",
    "floor_level_dict1 = dict.fromkeys(['1st','2nd','3rd','4th'],'low floors')\n",
    "floor_level_dict2 = dict.fromkeys(['mid floor','5th','6th','7th','8th','9th','10th','11th'],'mid floors')\n",
    "floor_level_dict3 = dict.fromkeys(['top floor','12th','13th','14th','15th','16th','17th','18th','19th','20th',\n",
    "                                   '21st or above'],'mid floors')\n",
    "floor_level_dict.update(floor_level_dict1)\n",
    "floor_level_dict.update(floor_level_dict2)\n",
    "floor_level_dict.update(floor_level_dict3)\n",
    "epc_train['floor_level'] = epc_train['FLOOR_LEVEL'].replace(floor_level_dict)\n",
    "epc_test['floor_level'] = epc_test['FLOOR_LEVEL'].replace(floor_level_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glazed Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "glazed_dict = dict.fromkeys(['double glazing installed before 2002','double glazing, unknown install date'],'old double glazing')\n",
    "glazed_dict1 = dict.fromkeys(['triple, known data','triple glazing'],'triple glazing')\n",
    "glazed_dict2 = dict.fromkeys(['secondary glazing','not defined','single glazing'],'old glazing')\n",
    "glazed_dict3 = dict.fromkeys(['double, known data','double glazing installed during or after 2002'],'double glazing')\n",
    "glazed_dict.update(glazed_dict1)\n",
    "glazed_dict.update(glazed_dict2)\n",
    "glazed_dict.update(glazed_dict3)\n",
    "glazed_dict['INVALID!'] = np.nan\n",
    "epc_train['glazed_type'] = epc_train['GLAZED_TYPE'].replace(glazed_dict)\n",
    "epc_test['glazed_type'] = epc_test['GLAZED_TYPE'].replace(glazed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_type_dict = dict.fromkeys(['Bungalow','Park home'],'one storey building')\n",
    "epc_train['property_type'] = epc_train['PROPERTY_TYPE'].replace(prop_type_dict)\n",
    "epc_test['property_type'] = epc_test['PROPERTY_TYPE'].replace(prop_type_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaid_dict['TRANSACTION_TYPE']['node1'].remove('<missing>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dict = dict.fromkeys(chaid_dict['TRANSACTION_TYPE']['node1'],'private rental and sale')\n",
    "trans_dict1 = dict.fromkeys(chaid_dict['TRANSACTION_TYPE']['node2'],'social rental and new build')\n",
    "trans_dict2 = dict.fromkeys(chaid_dict['TRANSACTION_TYPE']['node3'],'private rental and sale')\n",
    "trans_dict3 = dict.fromkeys(chaid_dict['TRANSACTION_TYPE']['node4'],'social rental and new build')\n",
    "#trans_dict4 = dict.fromkeys(chaid_dict['TRANSACTION_TYPE']['node5'],'assessment')\n",
    "trans_dict.update(trans_dict1)\n",
    "trans_dict.update(trans_dict2)\n",
    "trans_dict.update(trans_dict3)\n",
    "#trans_dict.update(trans_dict4)\n",
    "trans_dict['unknown'] = np.nan\n",
    "epc_train['transaction_type'] = epc_train['TRANSACTION_TYPE'].replace(trans_dict)\n",
    "epc_test['transaction_type'] = epc_test['TRANSACTION_TYPE'].replace(trans_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_dict = dict.fromkeys(['Blaenau Gwent','Neath Port Talbot','Pembrokeshire','Rhondda Cynon Taf','Caerphilly',\n",
    "                             'Flintshire','Carmarthenshire','Powys','Conwy','Ceredigion','Debighshire',\n",
    "                             'Gwynedd','Isle of Anglesey'],'rural')\n",
    "region_dict1 = dict.fromkeys(['Bridgend','Monmouthshire','Wrexham','Merthyr Tydfil','Vale of Glamorgan','Cardiff',\n",
    "                              'Torfaen','Newport','Swansea'],'suburban')\n",
    "region_dict.update(region_dict1)\n",
    "epc_train['locality'] = epc_train['region'].replace(region_dict)\n",
    "epc_test['locality'] = epc_test['region'].replace(region_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features that correlate with each other or are leading\n",
    "correlated_variables = ['CO2_EMISS_CURR_PER_FLOOR_AREA','CO2_EMISSIONS_CURRENT','ENERGY_CONSUMPTION_CURRENT',\n",
    "                     'HEATING_COST_CURRENT','HOT_WATER_COST_CURRENT','HOT_WATER_ENERGY_EFF','HOT_WATER_ENV_EFF',\n",
    "                     'LIGHTING_COST_CURRENT','LIGHTING_ENERGY_EFF','LIGHTING_ENV_EFF','LMK_KEY','LOW_ENERGY_LIGHTING',\n",
    "                     'MAIN_FUEL','MAINHEAT_ENERGY_EFF','MAINHEAT_ENV_EFF','MAINHEATC_ENERGY_EFF','MAINHEATC_ENV_EFF',\n",
    "                     'MAINHEATCONT_DESCRIPTION','MECHANICAL_VENTILATION','MULTI_GLAZE_PROPORTION','NUMBER_HEATED_ROOMS',\n",
    "                     'POSTCODE','ROOF_ENERGY_EFF','ROOF_ENV_EFF','SECONDHEAT_DESCRIPTION','WALLS_ENERGY_EFF',\n",
    "                     'WALLS_ENV_EFF','WINDOWS_ENERGY_EFF','WINDOWS_ENV_EFF']\n",
    "\n",
    "# features replace with binned features\n",
    "replace_features = ['region','CURRENT_ENERGY_RATING','PROPERTY_TYPE','BUILT_FORM','INSPECTION_DATE','TRANSACTION_TYPE',\n",
    "                   'ENERGY_TARIFF','FLOOR_LEVEL','GLAZED_TYPE','EXTENSION_COUNT','NUMBER_HABITABLE_ROOMS',\n",
    "                    'NUMBER_OPEN_FIREPLACES','HOTWATER_DESCRIPTION','FLOOR_DESCRIPTION','MAIN_HEATING_CONTROLS',\n",
    "                    'WINDOWS_DESCRIPTION','WALLS_DESCRIPTION','ROOF_DESCRIPTION','LIGHTING_DESCRIPTION',\n",
    "                    'FLOOR_HEIGHT']\n",
    "\n",
    "# other fields not needed\n",
    "fields_to_drop = ['floors_average_thermal_transmittance','low_energy_lighting_perc',\n",
    "                  'roof_average_thermal_transmittance','walls_average_thermal_transmittance',\n",
    "                  'floors_att','walls_att','roof_att','wall_insulation',\n",
    "                  'floor_insulation','roof_insulation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_train.drop(correlated_variables,axis = 1,inplace=True)\n",
    "epc_train.drop(replace_features,axis = 1,inplace=True)\n",
    "epc_train.drop(fields_to_drop,axis = 1,inplace=True)\n",
    "epc_test.drop(correlated_variables,axis = 1,inplace=True)\n",
    "epc_test.drop(replace_features,axis = 1,inplace=True)\n",
    "epc_test.drop(fields_to_drop,axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_train.to_csv(os.path.join(processing_path,epc_train_do_fname),index = False)\n",
    "epc_test.to_csv(os.path.join(processing_path,epc_test_do_fname),index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
