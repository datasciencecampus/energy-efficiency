{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script applies a linear regression model the data driven feature set, given a baseline preformance for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables from config file\n",
    "config_path = os.path.abspath('..')[:-7]\n",
    "\n",
    "with open(config_path + '/config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "processing_path = config['DEFAULT']['processing_path']\n",
    "epc_train_clean_fname = config['DEFAULT']['epc_train_clean_fname']\n",
    "epc_test_clean_fname = config['DEFAULT']['epc_test_clean_fname']\n",
    "epc_train_dd_fname = config['DEFAULT']['epc_train_dd_fname']\n",
    "epc_test_dd_fname = config['DEFAULT']['epc_test_dd_fname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_train = pd.read_csv(os.path.join(processing_path,epc_train_dd_fname),header = 0,delimiter = ',')\n",
    "epc_test = pd.read_csv(os.path.join(processing_path,epc_test_dd_fname),header = 0,delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_train.drop(['BUILDING_REFERENCE_NUMBER'],axis=1,inplace=True)\n",
    "epc_test.drop(['BUILDING_REFERENCE_NUMBER'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â one hot encode categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAINS_GAS_FLAG\n",
      "HEAT_LOSS_CORRIDOOR\n",
      "built_form\n",
      "energy_tariff\n",
      "floor_description\n",
      "floor_level\n",
      "glazed_type\n",
      "hotwater_description\n",
      "lighting_description\n",
      "mainheat_controls\n",
      "property_type\n",
      "roof_description\n",
      "transaction_type\n",
      "walls_description\n",
      "window_description\n",
      "locality\n",
      "extension\n",
      "floor_height\n",
      "habitable_rooms\n",
      "open_fireplaces\n"
     ]
    }
   ],
   "source": [
    "for col in ['MAINS_GAS_FLAG','HEAT_LOSS_CORRIDOOR','built_form','energy_tariff','floor_description','floor_level',\n",
    "            'glazed_type','hotwater_description','lighting_description','mainheat_controls','property_type',\n",
    "            'roof_description','transaction_type','walls_description','window_description','locality','extension',\n",
    "            'floor_height','habitable_rooms','open_fireplaces']:\n",
    "    print(col)\n",
    "    for_dummy = epc_train.pop(col)\n",
    "    epc_train = pd.concat([epc_train, pd.get_dummies(for_dummy, prefix=col)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAINS_GAS_FLAG\n",
      "HEAT_LOSS_CORRIDOOR\n",
      "built_form\n",
      "energy_tariff\n",
      "floor_description\n",
      "floor_level\n",
      "glazed_type\n",
      "hotwater_description\n",
      "lighting_description\n",
      "mainheat_controls\n",
      "property_type\n",
      "roof_description\n",
      "transaction_type\n",
      "walls_description\n",
      "window_description\n",
      "locality\n",
      "extension\n",
      "floor_height\n",
      "habitable_rooms\n",
      "open_fireplaces\n"
     ]
    }
   ],
   "source": [
    "for col in ['MAINS_GAS_FLAG','HEAT_LOSS_CORRIDOOR','built_form','energy_tariff','floor_description','floor_level',\n",
    "            'glazed_type','hotwater_description','lighting_description','mainheat_controls','property_type',\n",
    "            'roof_description','transaction_type','walls_description','window_description','locality','extension',\n",
    "            'floor_height','habitable_rooms','open_fireplaces']:\n",
    "    print(col)\n",
    "    for_dummy = epc_test.pop(col)\n",
    "    epc_test = pd.concat([epc_test, pd.get_dummies(for_dummy, prefix=col)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the target and features\n",
    "target_train = epc_train['CURRENT_ENERGY_EFFICIENCY']\n",
    "inputs_train = epc_train.drop('CURRENT_ENERGY_EFFICIENCY',axis=1)\n",
    "target_test = epc_test['CURRENT_ENERGY_EFFICIENCY']\n",
    "inputs_test = epc_test.drop('CURRENT_ENERGY_EFFICIENCY',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scale numeric values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_numeric(df,col):\n",
    "    \n",
    "    ''' \n",
    "    Fits a scaler called scaler to the specified column\n",
    "    Parameters\n",
    "      df: a dataframe\n",
    "      col: numeric variable to scale\n",
    "    Returns a dataframe\n",
    "    '''\n",
    "    \n",
    "    null_index = df[col].isnull()\n",
    "    df.loc[~null_index, [col]] = scaler.fit_transform(df.loc[~null_index, [col]])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = scale_numeric(inputs_train,'TOTAL_FLOOR_AREA')\n",
    "inputs_test = scale_numeric(inputs_test,'TOTAL_FLOOR_AREA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TOTAL_FLOOR_AREA    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epc_train[['TOTAL_FLOOR_AREA']].isnull().sum().sort_values(ascending = False) / epc_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/base.py:509: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initailise\n",
    "reg = LinearRegression()\n",
    "#train\n",
    "reg.fit(inputs_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [-1.37916981e+00 -5.28356088e-01  7.91677918e+00  1.29980232e+01\n",
      "  5.26393175e+00  6.96927031e+00  9.59837976e-01  4.39327574e+00\n",
      " -1.97265367e+00  1.22193902e+00  1.23333871e+01  4.03000395e-01\n",
      "  3.32764767e+00  6.41728029e+00  6.75564926e+00  6.17004795e-01\n",
      " -1.51612704e+00  1.51408500e+00 -3.24521026e+00  4.06227611e+00\n",
      " -6.89821161e-01 -6.16695082e-01  2.01034444e+00  3.68061500e+00\n",
      "  1.37972693e+00  1.24310303e-01  4.45646816e+00  1.79486639e+11\n",
      "  1.79486639e+11  1.79486639e+11  9.96339511e+00  8.63806331e+00\n",
      "  1.13528280e+01 -7.01001062e+00 -1.59963532e+01 -7.23443257e+00\n",
      " -6.07975551e+00 -9.85786021e+00 -2.73126887e+01  1.07144736e+12\n",
      "  1.07144736e+12  1.07144736e+12  1.07144736e+12  3.22093667e+12\n",
      "  3.22093667e+12  3.22093667e+12  3.22093667e+12  3.22093667e+12\n",
      "  3.22093667e+12  3.22093667e+12 -1.02127490e+00  1.90714604e+00\n",
      " -1.17647244e+00  1.77716141e-01 -9.66141668e+11 -9.66141668e+11\n",
      " -9.66141668e+11 -9.66141668e+11 -9.66141668e+11 -9.66141668e+11\n",
      " -5.18066506e+00 -8.50223328e+00 -3.96091058e+00  1.54537965e+10\n",
      "  1.54537965e+10 -4.37804412e+00 -4.59998503e+00 -4.74341989e+00\n",
      " -5.07874829e-01 -3.04855483e-01 -8.69538306e-01 -1.11106865e+00\n",
      " -1.79930105e+00 -3.09451630e+00 -7.43546534e+00 -6.14943472e+00\n",
      " -5.84514552e+00 -6.08589603e+00 -6.22653051e+00 -6.37991218e+00\n",
      "  5.49999043e-01 -3.00586732e+00 -6.18209771e+00]\n",
      "-3521182789871.162\n"
     ]
    }
   ],
   "source": [
    "#View the coefficients\n",
    "print('Coefficients: \\n', reg.coef_)\n",
    "\n",
    "#View the intercept\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance score: 0.7131\n",
      "Mean squared error: 72.9379\n"
     ]
    }
   ],
   "source": [
    "#Get performance on training data\n",
    "predict_train = reg.predict(inputs_train)\n",
    "train_r_squared = r2_score(target_train,predict_train)\n",
    "train_mse = mean_squared_error(target_train,predict_train)\n",
    "print('Variance score: %.4f' % train_r_squared)\n",
    "print(\"Mean squared error: %.4f\" % train_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance score: 0.7110\n",
      "Mean squared error: 72.6514\n"
     ]
    }
   ],
   "source": [
    "#Get performance on test data\n",
    "predict_test = reg.predict(inputs_test)\n",
    "test_r_squared = r2_score(target_test,predict_test)\n",
    "test_mse = mean_squared_error(target_test,predict_test)\n",
    "print('Variance score: %.4f' % test_r_squared)\n",
    "print(\"Mean squared error: %.4f\" % test_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
