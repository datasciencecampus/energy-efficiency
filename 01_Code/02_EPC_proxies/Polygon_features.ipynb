{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polygon Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The polygons provided by Ordnance Survey (OS) define building boundaries for domestic properties in Wales. These shapes were used to derive the area, length (perimeter), and uniformity (area/length) of a given building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import json\n",
    "import datetime as dt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables from config file\n",
    "config_path = os.path.abspath('..')\n",
    "\n",
    "with open(config_path + '/config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "polygon_path = config['DEFAULT']['polygon_path']\n",
    "polygon_fname = config['DEFAULT']['polygon_fname']\n",
    "uprn_lookup_fname = config['DEFAULT']['uprn_lookup_fname']\n",
    "lad_lookup_fname = config['DEFAULT']['lad_lookup_fname']\n",
    "buildings_fname = config['DEFAULT']['buildings_fname']\n",
    "building_height_fname = config['DEFAULT']['building_height_fname']\n",
    "built_form_fname = config['DEFAULT']['built_form_fname']\n",
    "polygon_features_fname = config['DEFAULT']['polygon_features_fname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "uprn2toid = pd.read_csv(os.path.join(polygon_path,uprn_lookup_fname))\n",
    "lad_lookup = pd.read_csv(os.path.join(polygon_path,lad_lookup_fname))\n",
    "building_heights = pd.read_csv(os.path.join(polygon_path,building_height_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building polygons\n",
    "# Change the co-ordinate reference system (CRS), note this takes a long time to run\n",
    "buildings = gpd.read_file(os.path.join(polygon_path,polygon_fname))\n",
    "buildings = buildings.to_crs({'init':'epsg:32630'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate features from the polygon shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings['area'] = buildings.geometry.area\n",
    "buildings['length'] = buildings.geometry.length\n",
    "buildings['uniformity1'] = buildings['area'] / buildings['length']\n",
    "buildings['cvx_hull_area'] = buildings.geometry.convex_hull.area\n",
    "buildings['uniformity2'] = buildings['area'] / buildings['cvx_hull_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_buildings = buildings.geometry.bounds\n",
    "tmp_buildings['y'] = tmp_buildings['maxy'] - tmp_buildings['miny']\n",
    "tmp_buildings['x'] = tmp_buildings['maxx'] - tmp_buildings['minx']\n",
    "tmp_buildings['AR'] = tmp_buildings[['x','y']].max(axis=1) / tmp_buildings[['x','y']].min(axis=1)\n",
    "buildings = pd.merge(buildings,\n",
    "                     tmp_buildings[['AR']],\n",
    "                     right_index = True,\n",
    "                     left_index = True,\n",
    "                     how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Five nearest neighbours based on distances between polygon centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to find each buildings five nearest neighbours. To reduce the time taken to process each building, \n",
    "# a flag for the local authority is joined and the search for neighbours is reduced to within the local authority\n",
    "\n",
    "# the local authority lookup is by uprn. To join local auhtority to toid an iterim dataset of one uprn to \n",
    "# toid is created\n",
    "uprn2toidone = uprn2toid.drop_duplicates(subset='toid',keep='first')\n",
    "\n",
    "uprn2toidone = pd.merge(uprn2toidone, lad_lookup, on = 'uprn', how = 'inner')\n",
    "\n",
    "# Merge the lad lookup onto the buildings data frame\n",
    "buildings = pd.merge(buildings, uprn2toidone, on = 'toid', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the LAD entries and drop unwanted entries\n",
    "lad_list = buildings['lad'].unique().tolist()\n",
    "lad_list.remove('unknown')\n",
    "lad_list.remove('Cheshire West and Chester')\n",
    "lad_list.remove('Shropshire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find nearest neighbour for each toid using the K nearest neighbour (KNN) algorithm. In this case K = 6 as the closest neighbour will be itself and will be excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_buffer = []\n",
    "for curr_lad in lad_list:\n",
    "    print('Processing:\\t', curr_lad)\n",
    "    # Extract relevant records and reset index\n",
    "    build_lad_slice = buildings.loc[buildings['lad'] == curr_lad,['uprn','geometry']]\n",
    "    build_lad_slice = build_lad_slice.reset_index()\n",
    "    \n",
    "    # Extract the components of the centroid and convert to a numpy array\n",
    "    build_lad_slice['x'] = build_lad_slice.centroid.x\n",
    "    build_lad_slice['y'] = build_lad_slice.centroid.y\n",
    "    #  Convert to a numpy array\n",
    "    nn_array = build_lad_slice[['x','y']].values\n",
    "    # Get NN (instantiate the sklearn object then 'train')\n",
    "    nn = NearestNeighbors(n_neighbors = 6, algorithm = 'ball_tree').fit(nn_array)\n",
    "    distances, indices = nn.kneighbors(nn_array)\n",
    "    # Convert the nparray to a dataframe (take the 2nd column because the 1st is\n",
    "    # the distance between each item and itself i.e. 0\n",
    "    nn = pd.DataFrame(distances)[[1,2,3,4,5]]\n",
    "    nn.rename(columns = {1:'nn_centroid',2:'nn_c2',3:'nn_c3',4:'nn_c4',5:'nn_c5'}, inplace = True)\n",
    "    \n",
    "    nn['nn_centroid_count'] = nn[['nn_centroid','nn_c2','nn_c3','nn_c4','nn_c5']].astype(bool).sum(axis=1)\n",
    "    \n",
    "    # Merge on the house centroids\n",
    "    build_lad_slice = pd.merge(build_lad_slice[['uprn']],\n",
    "                               nn,\n",
    "                               left_index = True,\n",
    "                               right_index = True,\n",
    "                               how = 'inner')\n",
    "    \n",
    "    # Add to the LAD buffer\n",
    "    buildings_buffer.append(build_lad_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the buffer into a single dataframe\n",
    "buildings_centroid_nn = pd.concat(buildings_buffer,ignore_index = True)\n",
    "\n",
    "\n",
    "# Merge back onto the buildings dataset\n",
    "buildings = pd.merge(buildings, buildings_centroid_nn, on = 'uprn', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Five nearest neighbours based on distances between polygon geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:\t Flintshire\n",
      "Processing:\t Denbighshire\n",
      "Processing:\t Wrexham\n",
      "Processing:\t Conwy\n",
      "Processing:\t Powys\n",
      "Processing:\t Monmouthshire\n",
      "Processing:\t Caerphilly\n",
      "Processing:\t Rhondda Cynon Taf\n",
      "Processing:\t Merthyr Tydfil\n",
      "Processing:\t Blaenau Gwent\n",
      "Processing:\t Torfaen\n",
      "Processing:\t Vale of Glamorgan\n",
      "Processing:\t Cardiff\n",
      "Processing:\t Newport\n",
      "Processing:\t Gwynedd\n",
      "Processing:\t Isle of Anglesey\n",
      "Processing:\t Pembrokeshire\n",
      "Processing:\t Carmarthenshire\n",
      "Processing:\t Ceredigion\n",
      "Processing:\t Swansea\n",
      "Processing:\t Neath Port Talbot\n",
      "Processing:\t Bridgend\n"
     ]
    }
   ],
   "source": [
    "buildings_buffer = []\n",
    "# del nn\n",
    "for curr_lad in lad_list:\n",
    "\n",
    "    print('Processing:\\t', curr_lad)\n",
    "\n",
    "    # Extract relevant records and reset index\n",
    "    build_lad_slice = buildings.loc[buildings['lad'] == curr_lad,['uprn','geometry']]\n",
    "    build_lad_slice = build_lad_slice.reset_index()\n",
    "\n",
    "    # Get the geometries into a look up dictionary\n",
    "    geometry_lookup = build_lad_slice['geometry'].to_dict()\n",
    "    uprn_lookup = build_lad_slice['uprn'].to_dict()\n",
    "\n",
    "    # Extract the components of the centroid and convert to a numpy array\n",
    "    build_lad_slice['x'] = build_lad_slice.centroid.x\n",
    "    build_lad_slice['y'] = build_lad_slice.centroid.y\n",
    "\n",
    "    #  Convert to a numpy array\n",
    "    nn_array = build_lad_slice[['x','y']].values\n",
    "\n",
    "    # Get NN (instantiate the sklearn object then 'train')\n",
    "    nn = NearestNeighbors(n_neighbors = 6, algorithm = 'ball_tree').fit(nn_array)\n",
    "    distances, indices = nn.kneighbors(nn_array)\n",
    "\n",
    "    # Convert the nparray to a dataframe (take the 2nd to 6th column because the 1st is\n",
    "    # the zeroth index\n",
    "    nn = pd.DataFrame(indices)[[1,2,3,4,5]]\n",
    "\n",
    "    # Get the geometrety for each NN\n",
    "    nn['geo1'] = nn[1].map(geometry_lookup)\n",
    "    nn['geo2'] = nn[2].map(geometry_lookup)\n",
    "    nn['geo3'] = nn[3].map(geometry_lookup)\n",
    "    nn['geo4'] = nn[4].map(geometry_lookup)\n",
    "    nn['geo5'] = nn[5].map(geometry_lookup)\n",
    "    \n",
    "    nn['uprn1'] = nn[1].map(uprn_lookup)\n",
    "    nn['uprn2'] = nn[2].map(uprn_lookup)\n",
    "    nn['uprn3'] = nn[3].map(uprn_lookup)\n",
    "    nn['uprn4'] = nn[4].map(uprn_lookup)\n",
    "    nn['uprn5'] = nn[5].map(uprn_lookup)\n",
    "    \n",
    "    # Merge on the house geometry\n",
    "    nn = pd.merge(build_lad_slice[['uprn','geometry']],\n",
    "                  nn[['geo1','geo2','geo3','geo4','geo5','uprn1','uprn2','uprn3','uprn4','uprn5']],\n",
    "                  left_index = True,\n",
    "                  right_index = True,\n",
    "                  how = 'inner')\n",
    "\n",
    "    # Get distances between geometries and take the minimum\n",
    "    nn['d1'] = nn.geometry.distance(gpd.GeoSeries(nn['geo1']))\n",
    "    nn['d2'] = nn.geometry.distance(gpd.GeoSeries(nn['geo2']))\n",
    "    nn['d3'] = nn.geometry.distance(gpd.GeoSeries(nn['geo3']))\n",
    "    nn['d4'] = nn.geometry.distance(gpd.GeoSeries(nn['geo4']))\n",
    "    nn['d5'] = nn.geometry.distance(gpd.GeoSeries(nn['geo5']))\n",
    "\n",
    "    nn['nn_geometry'] = nn[['d1','d2','d3','d4','d5']].min(axis = 1)\n",
    "    nn['nn_count'] = nn[['d1','d2','d3','d4','d5']].astype(bool).sum(axis=1)\n",
    "\n",
    "    # Add to the LAD buffer\n",
    "    buildings_buffer.append(nn[['uprn','nn_geometry','nn_count','uprn1','uprn2','uprn3','uprn4','uprn5',\n",
    "                               'd1','d2','d3','d4','d5']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the buffer into a single dataframe\n",
    "buildings_geometry_nn = pd.concat(buildings_buffer,ignore_index = True)\n",
    "\n",
    "# Merge back onto the buildings dataset\n",
    "buildings = pd.merge(buildings,\n",
    "                     buildings_geometry_nn,\n",
    "                     on = 'uprn',\n",
    "                     how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export interim dataset to use in another block_counts script\n",
    "buildings.to_csv(os.path.join(polygon_path,buildings_fname),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting building metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A building may contain multiple properties for instance a block of flats. The polygons capture the whole building outline and are recorded by topographic identifier (TOID) with a lookup for each Unique Property Reference Number (UPRN). A TOID represents an individual building which means for houses the data provides accurate information - shape, area, length and uniformity. However, for flats the exact details are unknown and the area and length have been divided equally between the properties in the building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on the uprn to the buildings dataset\n",
    "buildings = pd.merge(buildings, uprn2toid, on = 'toid', how = 'left')\n",
    "\n",
    "# Add a multiple toid count\n",
    "tmp = buildings['toid'].value_counts()\n",
    "tmp = tmp.to_frame(name = 'uprn_count').reset_index()\n",
    "tmp.rename(columns = {'index' : 'toid'}, inplace = True)\n",
    "\n",
    "buildings = pd.merge(buildings, tmp, on = 'toid', how = 'inner')\n",
    "\n",
    "# Adjust the metrics to account for multiple toids\n",
    "buildings['adj_area'] = buildings['area'] / buildings['uprn_count']\n",
    "buildings['adj_length'] = buildings['length'] / buildings['uprn_count']\n",
    "buildings['adj_uniformity1'] = buildings['adj_area'] / buildings['adj_length']\n",
    "buildings['adj_cvx_hull_area'] = buildings['cvx_hull_area'] / buildings['uprn_count']\n",
    "buildings['adj_uniformity2'] = buildings['adj_area'] / buildings['adj_cvx_hull_area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flats have been determined by counting the number of UPRNs within a toid. If the count is greater than one than the properties within the building are all deemed to be flats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings['flat'] = buildings.apply(lambda row: 1 if row['uprn_count'] > 1 else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging building heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = buildings.merge(building_heights, left_on = 'toid', right_on = 'TOID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings['adj_reH2'] = buildings['ReH2'] / buildings['uprn_count']\n",
    "buildings['adj_AbsHMax'] = buildings['AbsHMax'] / buildings['uprn_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.drop('uprn_x',inplace=True,axis=1)\n",
    "buildings.rename({'uprn_y':'uprn'},inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging built form from block_counts script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "built_form = pd.read_csv(os.path.join(polygon_path,built_form_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_complete = buildings.merge(built_form[['toid','built_form','block_count']], how = 'left',on='toid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_complete.to_csv(os.path.join(polygon_path,polygon_features_fname),index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
